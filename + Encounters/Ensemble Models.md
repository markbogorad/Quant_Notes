up:: [[Machine Learning Miscellaneous MOC]]
tags:: #Programming 
# Ensemble Models

Bagging vs Boosting Models
		- Bagging refers to the process of creating and merging a collection of independent, parallel decision trees using different subsets of the training data (bootstrapped datasets).
		- Boosting takes an iterative approach to combine a number of weak, sequential models to create one strong model by focusing on the mistakes of prior iterations.
	- AdaBoost Model -> not a great model (slow and suboptimal when compared to gradient boosting model)